{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the Trained Models\n",
    "\n",
    "Refer to the previous notebooks for the training job and hyperparameter tuning job names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "# Replace with your hyperparameter tuning job name below\n",
    "tuning_job_name=\"xgb-randsearch-20220412-18-10-58\"\n",
    "\n",
    "tuner = HyperparameterTuner.attach(tuning_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.best_training_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = tuner.deploy(initial_instance_count=1, instance_type=\"ml.m5.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import StringDeserializer\n",
    "\n",
    "predictor.serializer = CSVSerializer()\n",
    "predictor.deserializer = StringDeserializer()\n",
    "\n",
    "# Use Sample Data from 'test'\n",
    "predictor.predict(\"28,69,1.0,0,0,1,0,0,1,0,0,1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_data = pd.read_csv('test.csv', header=None)\n",
    "\n",
    "# Test data without labels\n",
    "test_data\n",
    "\n",
    "for index, row, in test_data.iterrows():\n",
    "    test_row = ','.join([str(i) for i in row.iloc[1:]])\n",
    "    prediction = predictor.predict(test_row)\n",
    "    print (\"Predicted {} for Passenger {}\".format(\n",
    "        prediction,\n",
    "        test_row))\n",
    "    print(f\"(True value was {row.iloc[0]})\")\n",
    "    test_data.loc[index, 'predicted'] = int(float(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "print(f\"accuracy {accuracy_score(test_data[0], test_data['predicted'])}\")\n",
    "conf_matrix = confusion_matrix(test_data[0], y_pred=test_data['predicted'])\n",
    "print(conf_matrix)\n",
    "sns.heatmap(conf_matrix, fmt='.3g', cmap='Blues', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Endpoint\n",
    "\n",
    "Not to incur charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker.Session().delete_endpoint(endpoint_name=predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Prediction\n",
    "\n",
    "Let's now run the inference as a Batch Transform Job\n",
    "\n",
    "We read our test CSV file, and remove the first column, which is what we want to predict (survival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "batchdf = pd.read_csv('test.csv',header=None)\n",
    "\n",
    "batchdf = batchdf.drop(columns=0)\n",
    "\n",
    "batchdf.to_csv(\"test_batch.csv\",header=False,index=False)\n",
    "\n",
    "input_batch = sagemaker_session.upload_data(path='test_batch.csv', key_prefix='titanic')\n",
    "\n",
    "batchdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a transformer object that inherits the model and container used in the best training job we got from the hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = tuner.best_training_job()\n",
    "estimator = sagemaker.estimator.Estimator.attach(job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normally you would not run batch manually, but trigger the batch prediction on an event \n",
    "# Some possible triggers would be: scheduled, a new file in S3\n",
    "\n",
    "from sagemaker.transformer import Transformer\n",
    "\n",
    "output_path='s3://{}/titanic'.format(bucket)\n",
    "\n",
    "xgb_batch_transformer = estimator.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    output_path=output_path\n",
    ")\n",
    "\n",
    "xgb_batch_transformer.base_transform_job_name='titanic-batch'\n",
    "\n",
    "xgb_batch_transformer.transform(\n",
    "    input_batch,\n",
    "    content_type='text/csv',\n",
    "    split_type='Line'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls {output_path}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp {output_path}/test_batch.csv.out ."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-central-1:936697816551:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
