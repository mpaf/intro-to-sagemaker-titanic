{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker XGBoost Algorithm\n",
    "\n",
    "We are going to use the XGBoost algorithm. Documentation can be found here:\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html\n",
    "\n",
    "For CSV training, the algorithm assumes that the target variable is in the first column and that the CSV does not have a header record.\n",
    "\n",
    "For a list of hyperparameters, have a look at:\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.inputs import TrainingInput\n",
    "import numpy as np\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# get the URI for the XGBoost container\n",
    "container_image = sagemaker.image_uris.retrieve(region=boto3.Session().region_name, framework='xgboost', version='latest')\n",
    "\n",
    "# build a SageMaker estimator class\n",
    "xgb_estimator = sagemaker.estimator.Estimator(\n",
    "    container_image,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    output_path='s3://{}/iris/output'.format(bucket),\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# set the hyperparameters\n",
    "xgb_estimator.set_hyperparameters(\n",
    "    max_depth=6,\n",
    "    eta=0.1,\n",
    "    gamma=0,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.7,\n",
    "    verbosity=1,\n",
    "    objective='multi:softmax',\n",
    "    num_class=2,\n",
    "    num_round=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uploading the Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the dataset to our S3 bucket\n",
    "input_train = sagemaker_session.upload_data(path='train.csv', key_prefix='titanic')\n",
    "input_val = sagemaker_session.upload_data(path='val.csv', key_prefix='titanic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run training against the training and val sets created above\n",
    "# Refer to the SageMaker training console\n",
    "\n",
    "content_type = \"csv\"\n",
    "train_input = TrainingInput(input_train, content_type=content_type)\n",
    "validation_input = TrainingInput(input_val, content_type=content_type)\n",
    "\n",
    "xgb_estimator.fit({\n",
    "    'train': train_input,\n",
    "    'validation': validation_input\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this result to be used in the next notebook\n",
    "xgb_estimator.latest_training_job.job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "\n",
    "objective_metric_name = \"validation:merror\"\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"alpha\": ContinuousParameter(0.01, 10, scaling_type=\"Logarithmic\"),\n",
    "    \"lambda\": ContinuousParameter(0.01, 10, scaling_type=\"Logarithmic\"),\n",
    "    \"eta\": ContinuousParameter(0, 1, scaling_type=\"Linear\"),\n",
    "    \"gamma\": ContinuousParameter(0, 10, scaling_type=\"Linear\")\n",
    "}\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    xgb_estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    max_jobs=9,\n",
    "    max_parallel_jobs=3,\n",
    "    strategy=\"Bayesian\",\n",
    "    objective_type='Minimize'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.fit({\n",
    "    'train': train_input,\n",
    "    'validation': validation_input\n",
    "    },\n",
    "    job_name=\"xgb-randsearch-\" + strftime(\"%Y%m%d-%H-%M-%S\", gmtime()),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.HyperparameterTuningJobAnalytics(\n",
    "    tuner.latest_tuning_job.job_name\n",
    ").dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.best_training_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this in the next notebook\n",
    "tuner.latest_tuning_job.job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now move to [Lab3](./3-Deploy.ipynb)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-central-1:936697816551:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
